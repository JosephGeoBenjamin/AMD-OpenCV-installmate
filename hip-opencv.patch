diff --git a/README.md b/README.md
index 200b2f7..5948774 100644
--- a/README.md
+++ b/README.md
@@ -1,13 +1,15 @@
 ## What is this repository for? ###
 
-HIP allows developers to convert CUDA code to portable C++.  The same source code can be compiled to run on NVIDIA or AMD GPUs. 
+HIP allows developers to convert CUDA code to portable C++.  The same source code can be compiled to run on NVIDIA or AMD GPUs.
 Key features include:
 
+Note: *Current branch is taken from roc-2.2.0. 3-component HIP_vector_type is implemented as static Array-type instead of ext_vector_type, to prevent 4*size alignment in memory buffer; Suitable Operator-overloads are provided.*
+
 * HIP is very thin and has little or no performance impact over coding directly in CUDA or hcc "HC" mode.
 * HIP allows coding in a single-source C++ programming language including features such as templates, C++11 lambdas, classes, namespaces, and more.
 * HIP allows developers to use the "best" development environment and tools on each target platform.
 * The "hipify" tool automatically converts source from CUDA to HIP.
-* Developers can specialize for the platform (CUDA or hcc) to tune for performance or handle tricky cases 
+* Developers can specialize for the platform (CUDA or hcc) to tune for performance or handle tricky cases
 
 New projects can be developed directly in the portable HIP C++ language and can run on either NVIDIA or AMD platforms.  Additionally, HIP provides porting tools which make it easy to port existing CUDA codes to the HIP layer, with no loss of performance as compared to the original CUDA application.  HIP is not intended to be a drop-in replacement for CUDA, and developers should expect to do some manual coding and performance tuning work to complete the port.
 
@@ -26,7 +28,7 @@ HIP releases are typically of two types. The tag naming convention is different
 * preview_x.yy.zzzz: These denote pre-release code and are based on the developer-preview branch. This type of release is typically made once a week.
 
 ## More Info:
-- [Installation](INSTALL.md) 
+- [Installation](INSTALL.md)
 - [HIP FAQ](docs/markdown/hip_faq.md)
 - [HIP Kernel Language](docs/markdown/hip_kernel_language.md)
 - [HIP Runtime API (Doxygen)](http://rocm-developer-tools.github.io/HIP)
@@ -45,7 +47,7 @@ HIP releases are typically of two types. The tag naming convention is different
 See the [Installation](INSTALL.md) notes.
 
 ## Simple Example
-The HIP API includes functions such as hipMalloc, hipMemcpy, and hipFree.  
+The HIP API includes functions such as hipMalloc, hipMemcpy, and hipFree.
 Programmers familiar with CUDA will also be able to quickly learn and start coding with the HIP API.
 Compute kernels are launched with the "hipLaunchKernel" macro call.    Here is simple example showing a
 snippet of HIP API code:
@@ -62,14 +64,14 @@ hipLaunchKernel(vector_square,   /* compute kernel*/
                 dim3(blocks), dim3(threadsPerBlock), 0/*dynamic shared*/, 0/*stream*/,     /* launch config*/
                 C_d, A_d, N);  /* arguments to the compute kernel */
 
-hipMemcpy(C_h, C_d, Nbytes, hipMemcpyDeviceToHost); 
+hipMemcpy(C_h, C_d, Nbytes, hipMemcpyDeviceToHost);
 ```
 
 
-The HIP kernel language defines builtins for determining grid and block coordinates, math functions, short vectors, 
-atomics, and timer functions. It also specifies additional defines and keywords for function types, address spaces, and 
+The HIP kernel language defines builtins for determining grid and block coordinates, math functions, short vectors,
+atomics, and timer functions. It also specifies additional defines and keywords for function types, address spaces, and
 optimization controls.  (See the [HIP Kernel Language](docs/markdown/hip_kernel_language.md) for a full description).
-Here's an example of defining a simple 'vector_square' kernel.  
+Here's an example of defining a simple 'vector_square' kernel.
 
 
 
@@ -91,12 +93,12 @@ The HIP Runtime API code and compute kernel definition can exist in the same sou
 
 ## HIP Portability and Compiler Technology
 HIP C++ code can be compiled with either :
-- On the NVIDIA CUDA platform, HIP provides header file which translate from the HIP runtime APIs to CUDA runtime APIs.  The header file contains mostly inlined 
+- On the NVIDIA CUDA platform, HIP provides header file which translate from the HIP runtime APIs to CUDA runtime APIs.  The header file contains mostly inlined
   functions and thus has very low overhead - developers coding in HIP should expect the same performance as coding in native CUDA.  The code is then
   compiled with nvcc, the standard C++ compiler provided with the CUDA SDK.  Developers can use any tools supported by the CUDA SDK including the CUDA
   profiler and debugger.
-- On the AMD ROCm platform, HIP provides a header and runtime library built on top of hcc compiler.  The HIP runtime implements HIP streams, events, and memory APIs, 
-  and is a object library that is linked with the application.  The source code for all headers and the library implementation is available on GitHub.  
+- On the AMD ROCm platform, HIP provides a header and runtime library built on top of hcc compiler.  The HIP runtime implements HIP streams, events, and memory APIs,
+  and is a object library that is linked with the application.  The source code for all headers and the library implementation is available on GitHub.
   HIP developers on ROCm can use AMD's CodeXL for debugging and profiling.
 
 Thus HIP source code can be compiled to run on either platform.  Platform-specific features can be isolated to a specific platform using conditional compilation.  Thus HIP
@@ -107,7 +109,7 @@ provides source portability to either platform.   HIP provides the _hipcc_ compi
 
 * A sample and [blog](http://gpuopen.com/hip-to-be-squared-an-introductory-hip-tutorial) that uses hipify to convert a simple app from CUDA to HIP:
 
- 
+
 ```shell
 cd samples/01_Intro/square
 # follow README / blog steps to hipify the application.
@@ -121,20 +123,20 @@ make
 
 * Guide to [Porting a New Cuda Project](docs/markdown/hip_porting_guide.md#porting-a-new-cuda-project")
 
- 
+
 ## More Examples
 The GitHub repository [HIP-Examples](https://github.com/ROCm-Developer-Tools/HIP-Examples.git) contains a hipified version of the popular Rodinia benchmark suite.
 The README with the procedures and tips the team used during this porting effort is here: [Rodinia Porting Guide](https://github.com/ROCm-Developer-Tools/HIP-Examples/blob/master/rodinia_3.0/hip/README.hip_porting)
 
 ## Tour of the HIP Directories
-* **include**: 
+* **include**:
     * **hip_runtime_api.h** : Defines HIP runtime APIs and can be compiled with many standard Linux compilers (hcc, GCC, ICC, CLANG, etc), in either C or C++ mode.
     * **hip_runtime.h** : Includes everything in hip_runtime_api.h PLUS hipLaunchKernel and syntax for writing device kernels and device functions.  hip_runtime.h can only be compiled with hcc.
     * **hcc_detail/**** , **nvcc_detail/**** : Implementation details for specific platforms.  HIP applications should not include these files directly.
     * **hcc.h** : Includes interop APIs for HIP and HCC
-    
+
 * **bin**: Tools and scripts to help with hip porting
-    * **hipify** : Tool to convert CUDA code to portable CPP.  Converts CUDA APIs and kernel builtins.  
+    * **hipify** : Tool to convert CUDA code to portable CPP.  Converts CUDA APIs and kernel builtins.
     * **hipcc** : Compiler driver that can be used to replace nvcc in existing CUDA code. hipcc will call nvcc or hcc depending on platform, and include appropriate platform-specific headers and libraries.
     * **hipconfig** : Print HIP configuration (HIP_PATH, HIP_PLATFORM, CXX config flags, etc)
     * **hipexamine.sh** : Script to scan directory, find all code, and report statistics on how much can be ported with HIP (and identify likely features not yet supported)
@@ -144,4 +146,3 @@ The README with the procedures and tips the team used during this porting effort
 ## Reporting an issue
 Use the [GitHub issue tracker](https://github.com/ROCm-Developer-Tools/HIP/issues).
 If reporting a bug, include the output of "hipconfig --full" and samples/1_hipInfo/hipInfo (if possible).
-
diff --git a/include/hip/hcc_detail/hip_vector_types.h b/include/hip/hcc_detail/hip_vector_types.h
index acfb164..58c96eb 100644
--- a/include/hip/hcc_detail/hip_vector_types.h
+++ b/include/hip/hcc_detail/hip_vector_types.h
@@ -34,7 +34,7 @@ THE SOFTWARE.
 
 #include "hip/hcc_detail/host_defines.h"
 
-#if !defined(_MSC_VER) || __HIP_DEVICE_COMPILE__
+#if !defined(_MSC_VER)
 #if defined(__clang__)
     #define __NATIVE_VECTOR__(n, ...) __attribute__((ext_vector_type(n)))
 #elif defined(__GNUC__) // N.B.: GCC does not support .xyzw syntax.
@@ -74,12 +74,13 @@ THE SOFTWARE.
         };
     };
 
+// ====================== Modified
     template<typename T>
     struct HIP_vector_base<T, 3> {
-        typedef T Native_vec_ __NATIVE_VECTOR__(3, T);
+        typedef T* Native_vec_ ;
 
         union {
-            Native_vec_ data;
+            T data[3];
             struct {
                 T x;
                 T y;
@@ -87,7 +88,7 @@ THE SOFTWARE.
             };
         };
     };
-
+//===========================
     template<typename T>
     struct HIP_vector_base<T, 4> {
         typedef T Native_vec_ __NATIVE_VECTOR__(4, T);
@@ -273,6 +274,222 @@ THE SOFTWARE.
         }
     };
 
+//========================= Size 3 arrays ======================================
+
+
+    template<typename T >
+    struct HIP_vector_type <T , 3>: public HIP_vector_base<T, 3> {
+        using HIP_vector_base<T, 3>::data;
+        using typename HIP_vector_base<T, 3>::Native_vec_;
+
+        __host__ __device__
+        HIP_vector_type() = default;
+        template<
+            typename U,
+            typename std::enable_if<
+                std::is_convertible<U, T>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type(U x) noexcept
+        {
+            for (auto i = 0u; i != 3; ++i) data[i] = x;
+        }
+        template< // TODO: constrain based on type as well.
+            typename... Us,
+            typename std::enable_if<
+                (3 > 1) && sizeof...(Us) == 3>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type(Us... xs) noexcept {
+            T data3[3] = {static_cast<T>(xs)...};
+            data[0] = data3[0];
+            data[1] = data3[1];
+            data[2] = data3[2];
+            }
+        __host__ __device__
+        HIP_vector_type(const HIP_vector_type&) = default;
+        __host__ __device__
+        HIP_vector_type(HIP_vector_type&&) = default;
+        __host__ __device__
+        ~HIP_vector_type() = default;
+
+        __host__ __device__
+        HIP_vector_type& operator=(const HIP_vector_type&) = default;
+        __host__ __device__
+        HIP_vector_type& operator=(HIP_vector_type&&) = default;
+
+        // Operators
+        __host__ __device__
+        HIP_vector_type& operator++() noexcept
+        {
+            this->data[0] += 1;
+            this->data[1] += 1;
+            this->data[2] += 1;
+            return *this;
+        }
+        __host__ __device__
+        HIP_vector_type operator++(int) noexcept
+        {
+            auto tmp(*this);
+            this->data[0] += 1;
+            this->data[1] += 1;
+            this->data[2] += 1;
+            return tmp;
+        }
+        __host__ __device__
+        HIP_vector_type& operator--() noexcept
+        {
+            this->data[0] -= 1;
+            this->data[1] -= 1;
+            this->data[2] -= 1;
+            return *this;
+        }
+        __host__ __device__
+        HIP_vector_type operator--(int) noexcept
+        {
+            auto tmp(*this);
+            this->data[0] -= 1;
+            this->data[1] -= 1;
+            this->data[2] -= 1;
+            return tmp;
+        }
+        __host__ __device__
+        HIP_vector_type& operator+=(const HIP_vector_type& x) noexcept
+        {
+            data[0] += x.data[0];
+            data[1] += x.data[1];
+            data[2] += x.data[2];
+            return *this;
+        }
+        __host__ __device__
+        HIP_vector_type& operator-=(const HIP_vector_type& x) noexcept
+        {
+            data[0] -= x.data[0];
+            data[1] -= x.data[1];
+            data[2] -= x.data[2];
+            return *this;
+        }
+        template<
+            typename U,
+            typename std::enable_if<
+                std::is_convertible<U, T>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator-=(U x) noexcept
+        {
+            data[0] -= x;
+            data[1] -= x;
+            data[2] -= x;
+            return *this;
+        }
+        __host__ __device__
+        HIP_vector_type& operator*=(const HIP_vector_type& x) noexcept
+        {
+            data[0] *= x.data[0];
+            data[1] *= x.data[1];
+            data[2] *= x.data[2];
+            return *this;
+        }
+        __host__ __device__
+        HIP_vector_type& operator/=(const HIP_vector_type& x) noexcept
+        {
+            data[0] /= x.data[0];
+            data[1] /= x.data[1];
+            data[2] /= x.data[2];
+            return *this;
+        }
+
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_signed<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type operator-() noexcept
+        {
+            auto tmp(*this);
+            tmp.data[0] = -tmp.data[0];
+            tmp.data[1] = -tmp.data[1];
+            tmp.data[2] = -tmp.data[2];
+            return tmp;
+        }
+
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type operator~() noexcept
+        {
+            T data_not[3];
+            data_not[0] = ~this->data[0];
+            data_not[1] = ~this->data[1];
+            data_not[2] = ~this->data[2];
+            return data_not;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator%=(const HIP_vector_type& x) noexcept
+        {
+            data[0] %= x.data[0];
+            data[1] %= x.data[1];
+            data[2] %= x.data[2];
+            return *this;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator^=(const HIP_vector_type& x) noexcept
+        {
+            data[0] ^= x.data[0];
+            data[1] ^= x.data[1];
+            data[2] ^= x.data[2];
+            return *this;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator|=(const HIP_vector_type& x) noexcept
+        {
+            data[0] |= x.data[0];
+            data[1] |= x.data[1];
+            data[2] |= x.data[2];
+            return *this;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator&=(const HIP_vector_type& x) noexcept
+        {
+            data[0] &= x.data[0];
+            data[1] &= x.data[1];
+            data[2] &= x.data[2];
+            return *this;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator>>=(const HIP_vector_type& x) noexcept
+        {
+            data[0] >>= x.data[0];
+            data[1] >>= x.data[1];
+            data[2] >>= x.data[2];
+            return *this;
+        }
+        template<
+            typename U = T,
+            typename std::enable_if<std::is_integral<U>{}>::type* = nullptr>
+        __host__ __device__
+        HIP_vector_type& operator<<=(const HIP_vector_type& x) noexcept
+        {
+            data[0] <<= x.data[0];
+            data[1] <<= x.data[1];
+            data[2] <<= x.data[2];
+            return *this;
+        }
+    };
+
+//==============================================================================
 
     template<typename T, unsigned int n>
     __host__ __device__
